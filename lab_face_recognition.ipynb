{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SICOM Face analysis\n",
    "In this lab we will process and play around with images of faces.\n",
    "\n",
    "The images used in this lab were extracted from the \"trombinoscope\" coming as a pdf file. They are shown below.\n",
    "As you can see the images show portraits with some differences in terms of size, head pose, quality of the image etc.\n",
    "<table><tr><td><img src=\"data/page-1.png\" style=\"width: 300px;\"/></td><td><img src=\"data/page-2.png\" style=\"width: 300px;\"/></td><td><img src=\"data/page-3.png\" style=\"width: 300px;\"/></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "The goal of this lab is to perform some automatic operations on the images presented above.\n",
    "1. Extract automatically the faces from an image\n",
    "2. Extract face landmarks (e.g., positions of eyes, mouth and nose)\n",
    "3. Align faces (geometrically transform images of faces)\n",
    "4. Segment faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "This lab will mainly rely on the following python libraries:\n",
    "- `open-cv`\n",
    "- `scikit-image`\n",
    "- `dlib`\n",
    "\n",
    "You can install these libraries with `pip install name_of_the_lib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install opencv-python\n",
    "# ! pip install scikit-image\n",
    "# ! pip install dlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function show an image using the matplotlib or opencv backend. You can change the default flag in the function.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Plot in an external window. The plot will be interactive.\n",
    "# Options for interactive plots are 'osx', 'qt4', 'qt5', 'gtk3', 'wx', 'qt', 'gtk', 'tk'...\n",
    "# %matplotlib widget \n",
    "#%matplotlib notebook\n",
    "\n",
    "# Plot inline, within the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "def show_img(img, img_name=\"fig\", flag='matplt'):\n",
    "    if flag== 'cv':\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    if flag == 'matplt': \n",
    "        plt.figure()\n",
    "        plt.imshow(img, cmap=plt.cm.gray)\n",
    "        plt.title(img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up output folder\n",
    "\n",
    "Results will be stored in a `output` folder in the current directory. Results for each part of the lab will be stored in a dedicated directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "outpath = os.path.join(\".\",\"output\")\n",
    "# create dir\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)\n",
    "    \n",
    "print(\"Output files will be saved in:\", outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Extract faces\n",
    "The first task we address is to crop the faces from the image. The goal is to generate a collection of images each one containing a face.\n",
    "\n",
    "Below, an example of the first three images extracted.\n",
    "\n",
    "<table><tr><td><img src=\"examples/face_00.png\" style=\"width: 200px;\"/></td><td><img src=\"examples/face_01.png\" style=\"width: 200px;\"/></td><td><img src=\"examples/face_02.png\" style=\"width: 200px;\"/></td></tr></table>\n",
    "\n",
    "### Question\n",
    "Define an algorithm for automatically extracting faces from the images. Implement it, run it on the input images in order to save the faces as separate images and explain your choices.\n",
    "\n",
    "You can use for example a pre-trained face detector. Open-CV offers an implementation of the face detection algorithm proposed by Viola and Jones, which is based on Haar features (a family of wavelets).\n",
    "See the corresponding tutorial.\n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html\n",
    "Attention that you may need to reduce the size of the image as it can take long time.\n",
    "\n",
    "Using a face detector can be a good strategy when processing a natural image containing faces. In our case, the image shows a structure that can be exploited. Here, each face is separated from the others and corresponds to a specific rectangular region in the image. You can exploit this fact for extracting the portraits from the image (withouth detecting explicitly the faces). In this case the alpha channel (4th channel) can be of interest.\n",
    "\n",
    "Other strategies can also be possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracting faces from an image\n",
    "# Take an image as input and give a list of images of faces\n",
    "\n",
    "import numpy as np\n",
    "from skimage import morphology\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "def extract_faces(img):\n",
    "    img_faces = []\n",
    "    # write your code here\n",
    "    # return a list of images (could be of different size), each one containing a portrait\n",
    "    return img_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img_files = ['data/page-96dpi-1.png', 'data/page-96dpi-2.png', 'data/page-96dpi-3.png']\n",
    "\n",
    "# set output folder\n",
    "outpath_folder = os.path.join(outpath,\"faces\")\n",
    "# create dir\n",
    "if not os.path.exists(outpath_folder):\n",
    "    os.makedirs(outpath_folder)\n",
    "\n",
    "# this variable will contain the list of face images extracted from the input images\n",
    "img_faces = []\n",
    "\n",
    "# cycle on the three input images\n",
    "for file in img_files:\n",
    "    # read the image\n",
    "    img = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    # extract faces and append them to the list\n",
    "    img_faces += extract_faces(img)\n",
    "    \n",
    "    \n",
    "print('Extracted %d faces' % len(img_faces))    \n",
    "\n",
    "\n",
    "# show the extracted faces\n",
    "#for f in img_faces:\n",
    "    #print(f.shape)\n",
    "    #show_img(f,flag=\"cv\")   \n",
    "    \n",
    "# show the extracted faces\n",
    "i = 0\n",
    "for f in img_faces:\n",
    "    cv2.imwrite((outpath_folder+'/face_%02d.png' % i), f)\n",
    "    i = i+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Face landmarks\n",
    "The goal of this part is to process each face image extracted in the previous part and extract face landmarks\n",
    "\n",
    "#### Download the pre-trained model here \n",
    "\n",
    "http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
    "\n",
    "- Place this file in your default ipython notebook folder -> it is already available in `/data`\n",
    "\n",
    "\n",
    "Below, an example of the first three images with extracted landmarks superimposed.\n",
    "\n",
    "<table><tr><td><img src=\"examples/face_00_landmarks.png\" style=\"width: 200px;\"/></td><td><img src=\"examples/face_01_landmarks.png\" style=\"width: 200px;\"/></td><td><img src=\"examples/face_02_landmarks.png\" style=\"width: 200px;\"/></td></tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Define some functions and utilities based on `dlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy\n",
    "from time import sleep\n",
    "import sys\n",
    "\n",
    "PREDICTOR_PATH = \"data/shape_predictor_68_face_landmarks.dat\"\n",
    "SCALE_FACTOR = 1 \n",
    "FEATHER_AMOUNT = 11\n",
    "\n",
    "FACE_POINTS = list(range(17, 68))\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "JAW_POINTS = list(range(0, 17))\n",
    "\n",
    "# Points used to line up the images.\n",
    "ALIGN_POINTS = (LEFT_BROW_POINTS + RIGHT_EYE_POINTS + LEFT_EYE_POINTS +\n",
    "                               RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS)\n",
    "\n",
    "# Points from the second image to overlay on the first. The convex hull of each\n",
    "# element will be overlaid.\n",
    "OVERLAY_POINTS = [\n",
    "    LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS,\n",
    "    NOSE_POINTS + MOUTH_POINTS,\n",
    "]\n",
    "\n",
    "# Amount of blur to use during colour correction, as a fraction of the\n",
    "# pupillary distance.\n",
    "COLOUR_CORRECT_BLUR_FRAC = 0.6\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from code from the book \"Master-Computer-Vision-OpenCV3-in-Python-and-Machine-Learning\" \n",
    "# https://github.com/PacktPublishing/Master-Computer-Vision-OpenCV3-in-Python-and-Machine-Learning\n",
    "class TooManyFaces(Exception):\n",
    "    pass\n",
    "\n",
    "class NoFaces(Exception):\n",
    "    pass\n",
    "\n",
    "def get_landmarks(im):\n",
    "    # Returns facial landmarks as (x,y) coordinates\n",
    "    rects = detector(im, 1)\n",
    "    \n",
    "    if len(rects) > 1:\n",
    "        raise TooManyFaces\n",
    "    if len(rects) == 0:\n",
    "        raise NoFaces\n",
    "\n",
    "    return numpy.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "\n",
    "def get_landmarks1(im):\n",
    "    # Returns facial landmarks as (x,y) coordinates\n",
    "    rects = detector(im, 1)\n",
    "    \n",
    "    return numpy.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "\n",
    "\n",
    "def annotate_landmarks(im, landmarks):\n",
    "    #Overlays the landmark points on the image itself\n",
    "    \n",
    "    im = im.copy()\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(im, str(idx), pos,\n",
    "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                    fontScale=0.4,\n",
    "                    color=(0, 0, 255))\n",
    "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
    "    return im\n",
    "def draw_convex_hull(im, points, color):\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(im, points, color=color)\n",
    "\n",
    "def get_face_mask(im, landmarks):\n",
    "    im = numpy.zeros(im.shape[:2], dtype=numpy.float64)\n",
    "\n",
    "    for group in OVERLAY_POINTS:\n",
    "        draw_convex_hull(im,\n",
    "                         landmarks[group],\n",
    "                         color=1)\n",
    "\n",
    "    im = numpy.array([im, im, im]).transpose((1, 2, 0))\n",
    "\n",
    "    im = (cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0) > 0) * 1.0\n",
    "    im = cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0)\n",
    "\n",
    "    return im\n",
    "    \n",
    "def transformation_from_points(points1, points2):\n",
    "    \"\"\"\n",
    "    Return an affine transformation [s * R | T] such that:\n",
    "        sum ||s*R*p1,i + T - p2,i||^2\n",
    "    is minimized.\n",
    "    \"\"\"\n",
    "    # Solve the procrustes problem by subtracting centroids, scaling by the\n",
    "    # standard deviation, and then using the SVD to calculate the rotation. See\n",
    "    # the following for more details:\n",
    "    #   https://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem\n",
    "\n",
    "    points1 = points1.astype(numpy.float64)\n",
    "    points2 = points2.astype(numpy.float64)\n",
    "\n",
    "    c1 = numpy.mean(points1, axis=0)\n",
    "    c2 = numpy.mean(points2, axis=0)\n",
    "    points1 -= c1\n",
    "    points2 -= c2\n",
    "\n",
    "    s1 = numpy.std(points1)\n",
    "    s2 = numpy.std(points2)\n",
    "    points1 /= s1\n",
    "    points2 /= s2\n",
    "\n",
    "    U, S, Vt = numpy.linalg.svd(points1.T * points2)\n",
    "\n",
    "    # The R we seek is in fact the transpose of the one given by U * Vt. This\n",
    "    # is because the above formulation assumes the matrix goes on the right\n",
    "    # (with row vectors) where as our solution requires the matrix to be on the\n",
    "    # left (with column vectors).\n",
    "    R = (U * Vt).T\n",
    "\n",
    "    return numpy.vstack([numpy.hstack(((s2 / s1) * R,\n",
    "                                       c2.T - (s2 / s1) * R * c1.T)),\n",
    "                         numpy.matrix([0., 0., 1.])])\n",
    "\n",
    "def read_im_and_landmarks(image):\n",
    "    im = image\n",
    "    im = cv2.resize(im,None,fx=1, fy=1, interpolation = cv2.INTER_LINEAR)\n",
    "    im = cv2.resize(im, (im.shape[1] * SCALE_FACTOR,\n",
    "                         im.shape[0] * SCALE_FACTOR))\n",
    "    s = get_landmarks(im)\n",
    "\n",
    "    return im, s\n",
    "\n",
    "def warp_im(im, M, dshape):\n",
    "    output_im = numpy.zeros(dshape, dtype=im.dtype)\n",
    "    cv2.warpAffine(im,\n",
    "                   M[:2],\n",
    "                   (dshape[1], dshape[0]),\n",
    "                   dst=output_im,\n",
    "                   borderMode=cv2.BORDER_TRANSPARENT,\n",
    "                   flags=cv2.WARP_INVERSE_MAP)\n",
    "    return output_im\n",
    "\n",
    "def correct_colours(im1, im2, landmarks1):\n",
    "    blur_amount = COLOUR_CORRECT_BLUR_FRAC * numpy.linalg.norm(\n",
    "                              numpy.mean(landmarks1[LEFT_EYE_POINTS], axis=0) -\n",
    "                              numpy.mean(landmarks1[RIGHT_EYE_POINTS], axis=0))\n",
    "    blur_amount = int(blur_amount)\n",
    "    if blur_amount % 2 == 0:\n",
    "        blur_amount += 1\n",
    "    im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0)\n",
    "    im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0)\n",
    "\n",
    "    # Avoid divide-by-zero errors.\n",
    "    im2_blur += (128 * (im2_blur <= 1.0)).astype(im2_blur.dtype)\n",
    "\n",
    "    return (im2.astype(numpy.float64) * im1_blur.astype(numpy.float64) /\n",
    "                                                im2_blur.astype(numpy.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract landmarks from the face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set output folder\n",
    "outpath_folder = os.path.join(outpath,\"landmarks\")\n",
    "# create dir\n",
    "if not os.path.exists(outpath_folder):\n",
    "    os.makedirs(outpath_folder)\n",
    "\n",
    "# extract landmarks\n",
    "i = 0\n",
    "undet_faces = []\n",
    "landmks = []\n",
    "for f in img_faces:\n",
    "    # landmarks = get_landmarks(f)\n",
    "    rects = detector(f, 1)\n",
    "    if len(rects) == 1: \n",
    "        landmarks = numpy.matrix([[p.x, p.y] for p in predictor(f, rects[0]).parts()])\n",
    "        landmks.append(landmarks)\n",
    "        image_with_landmarks = annotate_landmarks(f, landmarks)\n",
    "        cv2.imwrite((outpath_folder+'/face_%02d_landmarks.png' % i), image_with_landmarks)\n",
    "    else:\n",
    "        print('Extraction of landmarks failed on image n. %d' % i)\n",
    "        show_img(f, 'image %d' % i)\n",
    "        undet_faces.append(i)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "Landmarks extraction can fail on some images, due for example to noise. \n",
    "Define a pre-processing method to apply to those images in order to be able to extract the landmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Align images\n",
    "This part is devoted to align all face images extracted. Landmarks will be used for estimating a geometric transformation for warping an image to another.\n",
    "\n",
    "Below an example of three aligned faces. The first was used as reference and the other two were aligned on the first. After alignment, all images have the same size.\n",
    "\n",
    "<table><tr><td><img src=\"examples/face_00.png\" style=\"width: 200px;\"/></td><td><img src=\"examples/face_01_warped.png\" style=\"width: 200px;\"/></td><td><img src=\"examples/face_02_warped.png\" style=\"width: 200px;\"/></td></tr></table>\n",
    "\n",
    "### Question\n",
    "The code below performs the alignment taking an image as master and aligning all the others to this.\n",
    "Have a look to the code and try to understand what it does.\n",
    "\n",
    "You can now experiment for example by \n",
    "- modifying the master image\n",
    "- changing the set of facial landmarks used for the alignment\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face alignment\n",
    "# set output folder\n",
    "outpath_folder = os.path.join(outpath,\"align\")\n",
    "# create dir\n",
    "if not os.path.exists(outpath_folder):\n",
    "    os.makedirs(outpath_folder)\n",
    "\n",
    "fmaster = img_faces[0]\n",
    "lmaster = landmks[0]\n",
    "\n",
    "i = 1\n",
    "for f, l in zip(img_faces[1:],landmks[1:]):\n",
    "    M = transformation_from_points(lmaster[ALIGN_POINTS],\n",
    "                                   l[ALIGN_POINTS])\n",
    "    mask = get_face_mask(f, l)\n",
    "    warped_mask = warp_im(mask, M, fmaster.shape)\n",
    "    combined_mask = numpy.max([get_face_mask(fmaster, lmaster), warped_mask],\n",
    "                          axis=0)\n",
    "    warped_im2 = warp_im(f, M, fmaster.shape)\n",
    "    cv2.imwrite((outpath_folder+'/face_%02d_align.png' % i), warped_im2)\n",
    "    i = i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Face swapping\n",
    "\n",
    "Being able to establish correspondences among face images, allows one to do operations such as face swapping.\n",
    "See for example: https://matthewearl.github.io/2015/07/28/switching-eds-with-python/\n",
    "\n",
    "Implement a face swapping operator and apply it to two images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Face segmentation\n",
    "The face images that were extracted have different backgrounds. One could be interested in performing a segmentation of the image in order to extract the face as a region separated from the background. After segmentation, the background can be processed separately from the face region.\n",
    "\n",
    "### Question\n",
    "Tune the segmentation algorithm. For example you can change:\n",
    "- initial shape of the snake \n",
    "- blur applied to the image (`gaussian(img, ...)`)\n",
    "- parameters defining the internal energy of the snake \n",
    "\n",
    "### Optional\n",
    "Perform the face segmentation using another approach. You can for example exploit the position of the facial landmarks previously extracted. Run the algorithm on all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.path\n",
    "import numpy as np\n",
    "\n",
    "def pixels_inside_contour(polygon, size):\n",
    "    \n",
    "    i = np.arange(0, size[0])\n",
    "    j = np.arange(0, size[1])\n",
    "    xv, yv = np.meshgrid(i, j, indexing='ij')\n",
    "    points = np.hstack((xv.reshape((-1,1)), yv.reshape((-1,1))))\n",
    "\n",
    "    path = matplotlib.path.Path(polygon)\n",
    "    mask = path.contains_points(points)\n",
    "    mask.shape = xv.shape\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test face segmentation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import data\n",
    "from skimage.filters import gaussian\n",
    "from skimage.segmentation import active_contour\n",
    "\n",
    "# set output folder\n",
    "outpath_folder = os.path.join(outpath,\"segm\")\n",
    "# create dir\n",
    "if not os.path.exists(outpath_folder):\n",
    "    os.makedirs(outpath_folder)\n",
    "    \n",
    "\n",
    "# convert to grayscale\n",
    "img = cv2.cvtColor(img_faces[0], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# define the initial contour\n",
    "s = np.linspace(0, 2*np.pi, 400)\n",
    "r = 60 + 100*np.sin(s)\n",
    "c = 60 + 50*np.cos(s)\n",
    "init = np.array([r, c]).T\n",
    "\n",
    "# compute an active contour segmentation \n",
    "snake = active_contour(gaussian(img, 2.0),\n",
    "                       init, alpha=0.015, beta=75, gamma=0.001,\n",
    "                       coordinates='rc')\n",
    "\n",
    "# plot the init and final contour\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(img, cmap=plt.cm.gray)\n",
    "ax.plot(init[:, 1], init[:, 0], '--r', lw=3)\n",
    "ax.plot(snake[:, 1], snake[:, 0], '-b', lw=3)\n",
    "ax.set_xticks([]), ax.set_yticks([])\n",
    "ax.axis([0, img.shape[1], img.shape[0], 0])\n",
    "plt.savefig((outpath_folder+'/face_%02d_segm.png' % 0))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# get the pixels inside the contour and generate a binary mask\n",
    "mask = pixels_inside_contour(snake, img.shape)\n",
    "show_img(mask, \"mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "In this part you will process the image background.\n",
    "- Set the background pixel to an arbitrary value\n",
    "- Blur the background (e.g., by simulating a Bokeh effect https://en.wikipedia.org/wiki/Bokeh)\n",
    "- Blur the background with an increasing value of blur with respect to the distance from the face (you may use the `spipy` function `distance_transform_edt`)\n",
    "- Substitute the background with another one. Use a custom image as background. You may want to smooth the transition between foreground and background in order to reduce the effect of imprecisions in segmentation\n",
    "- ...\n",
    "\n",
    "Process all images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional\n",
    "Other possible developments:\n",
    "- Compute eigenfaces (https://en.wikipedia.org/wiki/Eigenface). These are features obtained by a eigendecomposition of a set of aligned faces. These features can be used for performing face recognition.\n",
    "In this case it is better to use images with blurred background or crop the images leaving only the face.\n",
    "Example: https://scipy-lectures.org/packages/scikit-learn/auto_examples/plot_eigenfaces.html\n",
    "- Knowing the position of facial landmarks (eyes, nose, mouth...) allows to perform some post-processing on the image. For example you can implement some \"make-up\" filters in order to perform some operations on the face. You can also add glasses, moustaches etc.\n",
    "- Cartoonize the images. You can run some segmentation algorithms on the image and perform vector quantization (giving the average color of a region to all its pixels)\n",
    "- ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
